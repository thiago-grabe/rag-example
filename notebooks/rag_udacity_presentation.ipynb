{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nThe objective of this notebook is to demonstrate how to create a Retrieval-Augmented Generation (RAG) system using:\\n1. Generated data about cars.\\n2. OpenAI's Embedding model to convert car descriptions to vectors.\\n3. Chroma as the in-memory vector database to store and retrieve relevant vectors.\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "import chromadb\n",
    "import numpy as np\n",
    "from chromadb.utils import embedding_functions\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Let's use Chroma to implement an in-memory vector store.\n",
    "# This example will use generated data about cars for embedding storage and retrieval.\n",
    "\n",
    "# Step 1: Install necessary packages (to be run in a notebook cell)\n",
    "# !pip install openai chromadb\n",
    "\n",
    "\"\"\"\n",
    "The objective of this notebook is to demonstrate how to create a Retrieval-Augmented Generation (RAG) system using:\n",
    "1. Generated data about cars.\n",
    "2. OpenAI's Embedding model to convert car descriptions to vectors.\n",
    "3. Chroma as the in-memory vector database to store and retrieve relevant vectors.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Setting up OpenAI key\n",
    "# Note: You need an OpenAI API key to proceed. Set it below.\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"YOUR_OPENAI_API_KEY\"\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import chromadb\n",
    "import numpy as np\n",
    "from chromadb.utils import embedding_functions\n",
    "\n",
    "# Let's use Chroma to implement an in-memory vector store.\n",
    "# This example will use generated data about cars for embedding storage and retrieval.\n",
    "\n",
    "# Step 1: Install necessary packages (to be run in a notebook cell)\n",
    "# !pip install openai chromadb\n",
    "\n",
    "\"\"\"\n",
    "The objective of this notebook is to demonstrate how to create a Retrieval-Augmented Generation (RAG) system using:\n",
    "1. Generated data about cars.\n",
    "2. OpenAI's Embedding model to convert car descriptions to vectors.\n",
    "3. Chroma as the in-memory vector database to store and retrieve relevant vectors.\n",
    "\"\"\"\n",
    "\n",
    "# Step 2: Setting up OpenAI key\n",
    "# Note: You need an OpenAI API key to proceed. Set it below.\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"YOUR_OPENAI_API_KEY\"\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "# Step 3: Generate data for the cars\n",
    "\"\"\"\n",
    "To simulate a real dataset, we'll generate information about cars. Each car will have a name, price, engine type, and description.\n",
    "The following data is used to showcase how information is stored and used in the vector database for retrieval.\n",
    "\"\"\"\n",
    "\n",
    "# Here we define a small set of initial car data manually.\n",
    "# This will serve as our base dataset to which we will later add more generated cars.\n",
    "cars = [\n",
    "    {\n",
    "        \"name\": \"Superfast Coupe 2024\",\n",
    "        \"price\": \"$80,000\",\n",
    "        \"engine\": \"V8 5.0L\",\n",
    "        \"description\": \"The Superfast Coupe 2024 offers a V8 engine, exceptional acceleration, and high-speed performance. It is ideal for sports car enthusiasts seeking adrenaline and sleek design.\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"EcoDrive Hatchback 2024\",\n",
    "        \"price\": \"$25,000\",\n",
    "        \"engine\": \"Electric\",\n",
    "        \"description\": \"The EcoDrive Hatchback 2024 is a fully electric vehicle, designed for urban environments with excellent range efficiency, a compact form factor, and environment-friendly features.\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Family SUV XL 2024\",\n",
    "        \"price\": \"$45,000\",\n",
    "        \"engine\": \"V6 3.5L\",\n",
    "        \"description\": \"The Family SUV XL 2024 is a spacious and versatile SUV that provides comfort, safety, and excellent driving dynamics for long journeys.\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Luxury Sedan Prime 2024\",\n",
    "        \"price\": \"$70,000\",\n",
    "        \"engine\": \"Hybrid\",\n",
    "        \"description\": \"The Luxury Sedan Prime 2024 offers a combination of luxury, efficiency, and hybrid technology, ensuring a comfortable and refined ride for passengers.\"\n",
    "    },\n",
    "]\n",
    "\n",
    "# Step 3a: Generate more car data using GPT-3\n",
    "\"\"\"\n",
    "To enhance the dataset, we will generate additional car entries using OpenAI's GPT-3 model.\n",
    "The generated data will include car name, price, engine type, and a detailed description.\n",
    "We will use a prompt to guide the model to return data in a consistent and predictable format.\n",
    "\"\"\"\n",
    "\n",
    "# Generate 50 car data entries using OpenAI GPT-3\n",
    "import openai\n",
    "\n",
    "def generate_car_data(num_cars=50):\n",
    "    \"\"\"\n",
    "    Generates car data using OpenAI's GPT-3 model.\n",
    "    Args:\n",
    "        num_cars (int): Number of car entries to generate.\n",
    "    Returns:\n",
    "        List[dict]: A list of dictionaries containing car details.\n",
    "    \"\"\"\n",
    "    car_data = []\n",
    "    for i in range(num_cars):\n",
    "        response = openai.Completion.create(\n",
    "            engine=\"text-davinci-003\",\n",
    "            prompt=(\n",
    "                \"Generate details for a car including the following fields: \\n\"\n",
    "                \"Name: <Car Name>\\n\"\n",
    "                \"Price: <Car Price>\\n\"\n",
    "                \"Engine: <Engine Type>\\n\"\n",
    "                \"Description: <Car Description>\\n\"\n",
    "                \"Please provide each field in the exact order and format as shown above.\"\n",
    "            ),\n",
    "            max_tokens=150\n",
    "        )\n",
    "        car_details = response.choices[0].text.strip().split('\\n')\n",
    "        try:\n",
    "            car = {\n",
    "                \"name\": car_details[0].split(': ')[1],\n",
    "                \"price\": car_details[1].split(': ')[1],\n",
    "                \"engine\": car_details[2].split(': ')[1],\n",
    "                \"description\": car_details[3].split(': ')[1]\n",
    "            }\n",
    "            car_data.append(car)\n",
    "        except IndexError:\n",
    "            print(f\"Error parsing car details for iteration {i}, skipping entry.\")\n",
    "            continue\n",
    "    return car_data\n",
    "\n",
    "# Append the generated cars to the existing cars list\n",
    "\"\"\"\n",
    "Here, we append the 50 generated cars to our initial dataset.\n",
    "This results in a dataset of 54 cars that will be used for embedding storage and retrieval.\n",
    "\"\"\"\n",
    "cars += generate_car_data(50)\n",
    "\n",
    "# Step 4: Initialize Chroma DB and prepare embeddings\n",
    "\"\"\"\n",
    "We will use OpenAI embeddings to convert the car descriptions into vectors, which can be easily stored and queried in Chroma.\n",
    "Chroma will serve as our in-memory vector database, allowing us to perform fast similarity searches for the car descriptions.\n",
    "\"\"\"\n",
    "\n",
    "# Set up Chroma and OpenAI embedding function\n",
    "client = chromadb.Client()\n",
    "openai_ef = embedding_functions.OpenAIEmbeddingFunction(api_key=openai.api_key)\n",
    "\n",
    "# Create a new collection for storing car embeddings\n",
    "\"\"\"\n",
    "A Chroma collection is similar to a table in a database.\n",
    "In this collection, we will store embeddings representing each car's description along with metadata such as car name, price, and engine type.\n",
    "\"\"\"\n",
    "car_collection = client.create_collection(name=\"car_collection\", embedding_function=openai_ef)\n",
    "\n",
    "# Add car data to the Chroma collection\n",
    "car_ids = [str(i) for i in range(len(cars))]\n",
    "car_descriptions = [car[\"description\"] for car in cars]\n",
    "car_metadata = [{\"name\": car[\"name\"], \"price\": car[\"price\"], \"engine\": car[\"engine\"]} for car in cars]\n",
    "\n",
    "\"\"\"\n",
    "Adding the car data to Chroma involves specifying unique IDs for each car, the descriptions to embed, and relevant metadata.\n",
    "The metadata will be useful for presenting information to the user when we query the database.\n",
    "\"\"\"\n",
    "car_collection.add(ids=car_ids, metadatas=car_metadata, documents=car_descriptions)\n",
    "\n",
    "# Step 5: Querying Chroma for information\n",
    "\"\"\"\n",
    "In this step, we will demonstrate how to query the Chroma collection to find relevant cars.\n",
    "We will use a natural language prompt to find cars that match specific requirements.\n",
    "The embeddings will allow us to determine the similarity between the query and the car descriptions.\n",
    "\"\"\"\n",
    "\n",
    "# Example query prompt\n",
    "prompt = \"I want a comfortable car for my family with good safety features.\"\n",
    "\n",
    "# Retrieve the top match from Chroma collection\n",
    "\"\"\"\n",
    "Using the `query` method, we search for the most relevant car based on the given prompt.\n",
    "The query will return the car description that is most similar to the provided input.\n",
    "\"\"\"\n",
    "results = car_collection.query(query_texts=[prompt], n_results=1)\n",
    "\n",
    "# Display the result\n",
    "\"\"\"\n",
    "Once we get the result, we extract the metadata for the recommended car, such as its name, price, and engine type.\n",
    "We then print out the recommended car's details for the user.\n",
    "\"\"\"\n",
    "result_metadata = results[\"metadatas\"][0][0]\n",
    "result_name = result_metadata[\"name\"]\n",
    "result_price = result_metadata[\"price\"]\n",
    "result_engine = result_metadata[\"engine\"]\n",
    "\n",
    "print(f\"Recommended Car: {result_name}\\nPrice: {result_price}\\nEngine: {result_engine}\")\n",
    "\n",
    "\"\"\"\n",
    "This result demonstrates how the RAG approach, combining embeddings and natural language queries, can provide users with relevant and personalized insights.\n",
    "For a user looking for a specific type of car, such as one that is comfortable for a family, our system can find the best match from the dataset.\n",
    "\"\"\"\n",
    "\n",
    "# Step 6: Adding docstrings and documentation\n",
    "\"\"\"\n",
    "We have documented each of the main functions and steps of this notebook to ensure clarity.\n",
    "The goal is for students and developers to be able to follow along and understand each part of the process step-by-step.\n",
    "The RAG system in this notebook is designed to handle simple car queries, but it could easily be extended to handle more sophisticated use cases.\n",
    "Consider adding additional metadata, optimizing the embedding model, or integrating a front-end for an interactive experience.\n",
    "\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
