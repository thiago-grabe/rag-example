{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Overview: Retrieval-Augmented Generation (RAG)\n",
    "\n",
    "## What is RAG?\n",
    "Retrieval-Augmented Generation (RAG) is an advanced AI framework that combines information retrieval with natural language generation. By integrating a vector database with a generative language model, RAG enhances the contextual relevance and accuracy of generated responses.\n",
    "\n",
    "## How Does This Project Use RAG?\n",
    "This project demonstrates the power of RAG by:\n",
    "1. Storing car descriptions as vector embeddings in a vector database (ChromaDB).\n",
    "2. Querying the database to retrieve the most relevant information based on user queries.\n",
    "3. Generating enriched and personalized responses using GPT-3.5.\n",
    "4. Enhancing engagement by visualizing results with realistic AI-generated images.\n",
    "\n",
    "## Key Features:\n",
    "- **Vector Database Integration**: Efficient storage and retrieval of car metadata.\n",
    "- **LLM-Driven Enrichment**: Personalized and human-like messages for recommendations.\n",
    "- **Image Generation**: Realistic car images for an engaging user experience.\n",
    "- **Retry Mechanism**: Robust reranking ensures reliable and context-aware outputs.\n",
    "\n",
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Setting Up the Environment\n",
    "\n",
    "In this step, we import the necessary libraries and configure the environment for our project. This includes tools for embedding generation, vector database storage, and API interactions.\n",
    "\n",
    "### Why Set Up the Environment?\n",
    "1. **Foundation for the Project**: Ensures all necessary tools and dependencies are available for subsequent steps.\n",
    "2. **Efficient Workflow**: Proper setup saves time and prevents errors during execution.\n",
    "\n",
    "### Workflow\n",
    "- Import required libraries like `openai`, `chromadb`, and `dotenv`.\n",
    "- Configure environment variables to securely manage sensitive information like API keys.\n",
    "- Ensure all dependencies are installed.\n",
    "\n",
    "### Code Highlights\n",
    "- **Library Imports**: Includes modules for embedding generation and vector storage.\n",
    "- **Environment Configuration**: Uses `dotenv` to securely load environment variables.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "import chromadb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from chromadb.utils import embedding_functions\n",
    "from IPython.display import Image, display\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Let's use Chroma to implement an in-memory vector store.\n",
    "# This example will use generated data about cars for embedding storage and retrieval.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Configuring OpenAI API Key\n",
    "\n",
    "This step ensures that the OpenAI API key is correctly configured, enabling us to access embedding and text generation functionalities.\n",
    "\n",
    "### Why Configure an API Key?\n",
    "1. **Authentication**: Required to interact with OpenAI’s API.\n",
    "2. **Secure Access**: Protects sensitive credentials using environment variables.\n",
    "\n",
    "### Workflow\n",
    "- Load the OpenAI API key from environment variables using `dotenv`.\n",
    "- Assign the API key to the `openai.api_key` variable.\n",
    "\n",
    "### Code Highlights\n",
    "- **Secure Storage**: Environment variables safeguard sensitive information.\n",
    "- **Ease of Use**: Allows seamless API access throughout the project.\n",
    "\n",
    "This step ensures secure and authenticated interactions with the OpenAI API.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Setting up OpenAI key\n",
    "# Note: You need an OpenAI API key to proceed. Set it below.\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Generating Car Data\n",
    "\n",
    "We simulate a real-world dataset by creating a collection of car descriptions. This dataset includes key fields like name, price, engine type, and description.\n",
    "\n",
    "### Why Generate Car Data?\n",
    "1. **Data for Embeddings**: Provides input for creating vector embeddings.\n",
    "2. **Simulated Real-World Scenario**: Demonstrates how the system works with structured data.\n",
    "\n",
    "### Workflow\n",
    "- Manually define a small dataset of cars with fields such as `name`, `price`, and `description`.\n",
    "- Use this dataset as the foundation for embeddings and retrieval.\n",
    "\n",
    "### Code Highlights\n",
    "- **Data Structure**: JSON-like format captures relevant car details.\n",
    "- **Dataset Flexibility**: Easy to expand for larger-scale applications.\n",
    "\n",
    "This step provides the initial dataset required for embedding storage and retrieval.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Generate data for the cars\n",
    "\"\"\"\n",
    "To simulate a real dataset, we'll generate information about cars. Each car will have a name, price, engine type, and description.\n",
    "The following data is used to showcase how information is stored and used in the vector database for retrieval.\n",
    "\"\"\"\n",
    "\n",
    "# Here we define a small set of initial car data manually.\n",
    "# This will serve as our base dataset to which we will later add more generated cars.\n",
    "cars = [\n",
    "    {\n",
    "        \"name\": \"Toyota Corolla 2024\",\n",
    "        \"price\": \"$25,000\",\n",
    "        \"engine\": \"1.8L Inline-4\",\n",
    "        \"year\": 2024,\n",
    "        \"country\": \"Japan\",\n",
    "        \"manufacturer\": \"Toyota\",\n",
    "        \"description\": \"The Toyota Corolla 2024 offers reliability, fuel efficiency, and a comfortable ride, making it an ideal choice for families and urban commuters.\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Ford Mustang GT 2024\",\n",
    "        \"price\": \"$45,000\",\n",
    "        \"engine\": \"5.0L V8\",\n",
    "        \"year\": 2024,\n",
    "        \"country\": \"United States\",\n",
    "        \"manufacturer\": \"Ford\",\n",
    "        \"description\": \"The Ford Mustang GT 2024 delivers exhilarating performance with its powerful V8 engine, sporty handling, and iconic design.\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"BMW 3 Series 2024\",\n",
    "        \"price\": \"$42,000\",\n",
    "        \"engine\": \"2.0L Turbo Inline-4\",\n",
    "        \"year\": 2024,\n",
    "        \"country\": \"Germany\",\n",
    "        \"manufacturer\": \"BMW\",\n",
    "        \"description\": \"The BMW 3 Series 2024 is a luxury sedan offering a perfect balance of performance, style, and advanced technology.\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Hyundai Ioniq 5 2024\",\n",
    "        \"price\": \"$39,000\",\n",
    "        \"engine\": \"Electric\",\n",
    "        \"year\": 2024,\n",
    "        \"country\": \"South Korea\",\n",
    "        \"manufacturer\": \"Hyundai\",\n",
    "        \"description\": \"The Hyundai Ioniq 5 2024 is a fully electric SUV with a futuristic design, exceptional range, and innovative features.\"\n",
    "    },\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nTo enhance the dataset, we will generate additional car entries using OpenAI's GPT-3 model.\\nThe generated data will include car name, price, engine type, and a detailed description.\\nWe will use a prompt to guide the model to return data in a consistent and predictable format.\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3a: Generate more car data using GPT-3\n",
    "\"\"\"\n",
    "To enhance the dataset, we will generate additional car entries using OpenAI's GPT-3 model.\n",
    "The generated data will include car name, price, engine type, and a detailed description.\n",
    "We will use a prompt to guide the model to return data in a consistent and predictable format.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3a: Expanding the Dataset Using GPT-3\n",
    "\n",
    "To enhance the dataset, we dynamically generate more car data using GPT-3, ensuring variety and uniqueness.\n",
    "\n",
    "### Why Use GPT-3 for Data Generation?\n",
    "1. **Scalability**: Automates the creation of large datasets.\n",
    "2. **Diversity**: Produces varied and realistic data entries.\n",
    "\n",
    "### Workflow\n",
    "- Prompt GPT-3 with specific instructions to generate new car entries.\n",
    "- Ensure unique entries by checking against existing data.\n",
    "\n",
    "### Code Highlights\n",
    "- **Prompt Engineering**: Guides GPT-3 to produce consistent and structured output.\n",
    "- **Duplicate Checks**: Ensures no repeated entries in the dataset.\n",
    "\n",
    "This step expands the dataset, enabling more robust testing and retrieval.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate car detected: Zenith Zephyr. Skipping entry. Current Number of cars: 5.\n",
      "Duplicate car detected: Zenith Zephyr. Skipping entry. Current Number of cars: 6.\n",
      "Duplicate car detected: Thunderbolt GT. Skipping entry. Current Number of cars: 11.\n",
      "Duplicate car detected: Zenith Zephyr. Skipping entry. Current Number of cars: 11.\n",
      "Duplicate car detected: Zenith Zephyr. Skipping entry. Current Number of cars: 11.\n",
      "Duplicate car detected: Zenith GT. Skipping entry. Current Number of cars: 13.\n",
      "Duplicate car detected: Sakura GT. Skipping entry. Current Number of cars: 14.\n",
      "Duplicate car detected: Zenith Zephyr. Skipping entry. Current Number of cars: 17.\n",
      "Duplicate car detected: Sakura GT. Skipping entry. Current Number of cars: 17.\n",
      "Duplicate car detected: Thunderbolt GT. Skipping entry. Current Number of cars: 17.\n",
      "Duplicate car detected: Zenith GT. Skipping entry. Current Number of cars: 22.\n",
      "Duplicate car detected: Zenith Zephyr. Skipping entry. Current Number of cars: 22.\n",
      "Duplicate car detected: Zenith Zephyr. Skipping entry. Current Number of cars: 22.\n",
      "Duplicate car detected: Sakura GTZ. Skipping entry. Current Number of cars: 23.\n",
      "Duplicate car detected: Zenith X9. Skipping entry. Current Number of cars: 24.\n"
     ]
    }
   ],
   "source": [
    "def generate_car_data(num_cars=50, existing_names=None):\n",
    "    \"\"\"\n",
    "    Generates car data using OpenAI's GPT-3 model.\n",
    "    Args:\n",
    "        num_cars (int): Number of car entries to generate.\n",
    "    Returns:\n",
    "        List[dict]: A list of dictionaries containing car details.\n",
    "    \"\"\"\n",
    "    if not existing_names:\n",
    "        existing_names = set()\n",
    "    car_data = []\n",
    "    while len(car_data) < num_cars:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": (\n",
    "                    \"You are an expert assistant tasked with creating unique and realistic car entries. \"\n",
    "                    \"Each car entry must have a unique name and be described in detail.\"\n",
    "                    \"Create cars for countries like Japan, Germany, South Korea, and the United States.\"\n",
    "                )},\n",
    "                {\"role\": \"user\", \"content\": (\n",
    "                    \"Generate details for a car including the following fields: \\n\"\n",
    "                    \"Name: <Unique Car Name using creative names>\\n\"\n",
    "                    \"Price: <Car Price>\\n\"\n",
    "                    \"Engine: <Engine Type with details if electric, combustion or hibrid.>\\n\"\n",
    "                    \"Year: <Manufacturing Year>\\n\"\n",
    "                    \"Country: <Country of Origin>\\n\"\n",
    "                    \"Manufacturer: <Car Manufacturing Company>\\n\"\n",
    "                    \"Description: <Detailed description of the Car>\\n\"\n",
    "                    \"Ensure that the car name is not a duplicate and provide realistic and varied entries.\"\n",
    "                )}\n",
    "            ],\n",
    "            max_tokens=200\n",
    "        )\n",
    "        car_details = response['choices'][0]['message']['content'].strip().split('\\n')\n",
    "        try:\n",
    "            car = {\n",
    "                \"name\": car_details[0].split(': ')[1],\n",
    "                \"price\": car_details[1].split(': ')[1],\n",
    "                \"engine\": car_details[2].split(': ')[1],\n",
    "                \"year\": int(car_details[3].split(': ')[1]),\n",
    "                \"country\": car_details[4].split(': ')[1],\n",
    "                \"manufacturer\": car_details[5].split(': ')[1],\n",
    "                \"description\": car_details[6].split(': ')[1]\n",
    "            }\n",
    "            if car['name'] not in existing_names:\n",
    "                existing_names.add(car['name'])\n",
    "                car_data.append(car)\n",
    "            else:\n",
    "                print(f\"Duplicate car detected: {car['name']}. Skipping entry. Current Number of cars: {len(car_data)}.\")\n",
    "        except IndexError:\n",
    "            continue\n",
    "    return car_data\n",
    "\n",
    "# Append the generated cars to the existing cars list\n",
    "\"\"\"\n",
    "Here, we append the 26 generated cars to our initial dataset.\n",
    "This results in a dataset of 30 cars that will be used for embedding storage and retrieval.\n",
    "\"\"\"\n",
    "cars += generate_car_data(26)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Initializing ChromaDB and Preparing Embeddings\n",
    "\n",
    "This step involves setting up ChromaDB, an in-memory vector database, and generating embeddings for the car descriptions.\n",
    "\n",
    "### Why Use ChromaDB?\n",
    "1. **Efficient Storage**: Stores vector embeddings for fast retrieval.\n",
    "2. **Scalable Queries**: Handles similarity-based searches effectively.\n",
    "\n",
    "### Workflow\n",
    "- Initialize a ChromaDB client and create a collection for car embeddings.\n",
    "- Convert car descriptions into embeddings using OpenAI’s models.\n",
    "\n",
    "### Code Highlights\n",
    "- **Embedding Generation**: Leverages OpenAI’s `text-embedding-ada-002` model.\n",
    "- **Database Integration**: Uses ChromaDB for vector storage and retrieval.\n",
    "\n",
    "This step prepares the system for embedding-based similarity searches.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Initialize Chroma DB and prepare embeddings\n",
    "\"\"\"\n",
    "We will use OpenAI embeddings to convert the car descriptions into vectors, which can be easily stored and queried in Chroma.\n",
    "Chroma will serve as our in-memory vector database, allowing us to perform fast similarity searches for the car descriptions.\n",
    "\"\"\"\n",
    "\n",
    "# Set up Chroma and OpenAI embedding function\n",
    "client = chromadb.Client()\n",
    "openai_ef = embedding_functions.OpenAIEmbeddingFunction(api_key=openai.api_key, \n",
    "                                                        model_name=\"text-embedding-ada-002\")\n",
    "\n",
    "# Create a new collection for storing car embeddings\n",
    "\"\"\"\n",
    "A Chroma collection is similar to a table in a database.\n",
    "In this collection, we will store embeddings representing each car's description along with metadata such as car name, price, and engine type.\n",
    "\"\"\"\n",
    "car_collection = client.create_collection(name=\"car_collection\", embedding_function=openai_ef)\n",
    "\n",
    "# Add car data to the Chroma collection\n",
    "car_ids = [str(i) for i in range(len(cars))]\n",
    "car_descriptions = [car[\"description\"] for car in cars]\n",
    "car_metadata = [{\n",
    "    \"name\": car[\"name\"],\n",
    "    \"price\": car[\"price\"],\n",
    "    \"engine\": car[\"engine\"],\n",
    "    \"year\": car[\"year\"],\n",
    "    \"country\": car[\"country\"],\n",
    "    \"manufacturer\": car[\"manufacturer\"]\n",
    "} for car in cars]\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Adding the car data to Chroma involves specifying unique IDs for each car, the descriptions to embed, and relevant metadata.\n",
    "The metadata will be useful for presenting information to the user when we query the database.\n",
    "\"\"\"\n",
    "car_collection.add(ids=car_ids, metadatas=car_metadata, documents=car_descriptions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\Sample 5 Cars Entry in the Collection:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>engine</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>name</th>\n",
       "      <th>price</th>\n",
       "      <th>year</th>\n",
       "      <th>description</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Japan</td>\n",
       "      <td>Hybrid - 2.0L turbocharged inline-4 paired wit...</td>\n",
       "      <td>Sakura Motors</td>\n",
       "      <td>Sakura GT1</td>\n",
       "      <td>$60,000</td>\n",
       "      <td>2023</td>\n",
       "      <td>The Sakura GT1 is a stunning hybrid sports car...</td>\n",
       "      <td>[0.01086550671607256, 0.024016402661800385, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Japan</td>\n",
       "      <td>Hybrid - Combustion engine paired with an elec...</td>\n",
       "      <td>Zenith Motors</td>\n",
       "      <td>Zenith GT</td>\n",
       "      <td>$70,000</td>\n",
       "      <td>2023</td>\n",
       "      <td>The Zenith GT is a sleek and sporty hybrid cou...</td>\n",
       "      <td>[-0.011691463179886341, 0.01499741431325674, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Japan</td>\n",
       "      <td>Hybrid engine (combustion engine coupled with ...</td>\n",
       "      <td>Sakura Motors</td>\n",
       "      <td>Pulsar GT</td>\n",
       "      <td>$35,000</td>\n",
       "      <td>2023</td>\n",
       "      <td>The Pulsar GT by Sakura Motors is a cutting-ed...</td>\n",
       "      <td>[0.0014512534253299236, 0.020528066903352737, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Japan</td>\n",
       "      <td>Electric</td>\n",
       "      <td>Sakura Motors</td>\n",
       "      <td>Sakura X1</td>\n",
       "      <td>$35,000</td>\n",
       "      <td>2023</td>\n",
       "      <td>The Sakura X1 is a futuristic electric car des...</td>\n",
       "      <td>[0.03706517070531845, 0.024505235254764557, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>United States</td>\n",
       "      <td>Electric</td>\n",
       "      <td>Tesla Motors</td>\n",
       "      <td>Zenith Electra</td>\n",
       "      <td>$45,000</td>\n",
       "      <td>2023</td>\n",
       "      <td>The Zenith Electra is a sleek and futuristic e...</td>\n",
       "      <td>[0.0003905900230165571, -0.0114307114854455, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          country                                             engine  \\\n",
       "20          Japan  Hybrid - 2.0L turbocharged inline-4 paired wit...   \n",
       "6           Japan  Hybrid - Combustion engine paired with an elec...   \n",
       "21          Japan  Hybrid engine (combustion engine coupled with ...   \n",
       "14          Japan                                           Electric   \n",
       "24  United States                                           Electric   \n",
       "\n",
       "     manufacturer            name    price  year  \\\n",
       "20  Sakura Motors      Sakura GT1  $60,000  2023   \n",
       "6   Zenith Motors       Zenith GT  $70,000  2023   \n",
       "21  Sakura Motors       Pulsar GT  $35,000  2023   \n",
       "14  Sakura Motors       Sakura X1  $35,000  2023   \n",
       "24   Tesla Motors  Zenith Electra  $45,000  2023   \n",
       "\n",
       "                                          description  \\\n",
       "20  The Sakura GT1 is a stunning hybrid sports car...   \n",
       "6   The Zenith GT is a sleek and sporty hybrid cou...   \n",
       "21  The Pulsar GT by Sakura Motors is a cutting-ed...   \n",
       "14  The Sakura X1 is a futuristic electric car des...   \n",
       "24  The Zenith Electra is a sleek and futuristic e...   \n",
       "\n",
       "                                            embedding  \n",
       "20  [0.01086550671607256, 0.024016402661800385, -0...  \n",
       "6   [-0.011691463179886341, 0.01499741431325674, 0...  \n",
       "21  [0.0014512534253299236, 0.020528066903352737, ...  \n",
       "14  [0.03706517070531845, 0.024505235254764557, 0....  \n",
       "24  [0.0003905900230165571, -0.0114307114854455, 0...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display all data in the collection as a pandas DataFrame\n",
    "\"\"\"\n",
    "We will now retrieve all metadata from the Chroma collection and display it as a pandas DataFrame.\n",
    "This provides a clear view of the data stored in the collection.\n",
    "\"\"\"\n",
    "# Retrieve all metadata, embeddings, and documents (descriptions) from the Chroma collection\n",
    "all_metadata = car_collection.get(ids=car_ids, include=[\"embeddings\", \"documents\", \"metadatas\"])\n",
    "\n",
    "# Create a DataFrame from the metadata\n",
    "car_data = pd.DataFrame(all_metadata['metadatas'])\n",
    "car_data[\"description\"] = all_metadata['documents']\n",
    "car_data[\"embedding\"] = all_metadata['embeddings'] \n",
    "print(\"\\Sample 5 Cars Entry in the Collection:\")\n",
    "car_data.sample(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Querying ChromaDB for Information\n",
    "\n",
    "This step demonstrates querying the ChromaDB collection to retrieve relevant cars based on user queries.\n",
    "\n",
    "### Why Query ChromaDB?\n",
    "1. **Retrieve Relevant Data**: Finds the most similar entries to a given query.\n",
    "2. **Natural Language Interface**: Allows users to search using everyday language.\n",
    "\n",
    "### Workflow\n",
    "- Use natural language prompts to query the vector database.\n",
    "- Retrieve and display relevant metadata and descriptions.\n",
    "\n",
    "### Code Highlights\n",
    "- **Similarity Search**: Retrieves the top matches based on vector embeddings.\n",
    "- **Flexible Queries**: Handles diverse user inputs effectively.\n",
    "\n",
    "This step showcases the retrieval capabilities of the RAG system.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The user's prompt is: I need a luxury sedan with a hybrid engine for a comfortable commute.\n",
      "Recommended Car: Toyota Corolla 2024\n",
      "Price: $25,000\n",
      "Engine: 1.8L Inline-4\n",
      "Year: 2024\n",
      "Manufacturer: Toyota\n",
      "Country: Japan\n",
      "Description: The Toyota Corolla 2024 offers reliability, fuel efficiency, and a comfortable ride, making it an ideal choice for families and urban commuters.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nThis result demonstrates how the RAG approach, combining embeddings and natural language queries, can provide users with relevant and personalized insights.\\nFor a user looking for a specific type of car, such as one that is comfortable for a family, our system can find the best match from the dataset.\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 5: Querying Chroma for information\n",
    "\"\"\"\n",
    "In this step, we will demonstrate how to query the Chroma collection to find relevant cars.\n",
    "We will use a natural language prompt to find cars that match specific requirements.\n",
    "The embeddings will allow us to determine the similarity between the query and the car descriptions.\n",
    "\"\"\"\n",
    "\n",
    "# Example query prompt\n",
    "prompts = [\n",
    "    \"I want a comfortable car for my family with good safety features.\",\n",
    "    \"Looking for a sporty car with high speed and acceleration.\",\n",
    "    \"Find me an eco-friendly electric car for urban use in the United States.\",\n",
    "    \"I need a luxury sedan with a hybrid engine for a comfortable commute.\",\n",
    "    \"Suggest an affordable car with great fuel efficiency for a student.\"\n",
    "]\n",
    "\n",
    "prompt = np.random.choice(prompts)\n",
    "print(f\"The user's prompt is: {prompt}\")\n",
    "\n",
    "# Retrieve the top match from Chroma collection\n",
    "\"\"\"\n",
    "Using the `query` method, we search for the most relevant car based on the given prompt.\n",
    "The query will return the car description that is most similar to the provided input.\n",
    "\"\"\"\n",
    "results = car_collection.query(query_texts=[prompt], n_results=1)\n",
    "\n",
    "# Display the result\n",
    "\"\"\"\n",
    "Once we get the result, we extract the metadata for the recommended car, such as its name, price, and engine type.\n",
    "We then print out the recommended car's details for the user.\n",
    "\"\"\"\n",
    "result_metadata = results[\"metadatas\"][0][0]\n",
    "result_name = result_metadata[\"name\"]\n",
    "result_price = result_metadata[\"price\"]\n",
    "result_engine = result_metadata[\"engine\"]\n",
    "result_year = result_metadata[\"year\"]\n",
    "result_manufacture = result_metadata[\"manufacturer\"]\n",
    "result_country = result_metadata[\"country\"]\n",
    "result_description = results['documents']\n",
    "\n",
    "print(f\"Recommended Car: {result_name}\\nPrice: {result_price}\\nEngine: {result_engine}\\nYear: {result_year}\\nManufacturer: {result_manufacture}\\nCountry: {result_country}\\nDescription: {result_description[0][0]}\")\n",
    "\n",
    "\"\"\"\n",
    "This result demonstrates how the RAG approach, combining embeddings and natural language queries, can provide users with relevant and personalized insights.\n",
    "For a user looking for a specific type of car, such as one that is comfortable for a family, our system can find the best match from the dataset.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The user's prompt is: I need a luxury sedan with a hybrid engine for a comfortable commute.\n",
      "\n",
      "Result 1:\n",
      "Name: Zenith Electra\n",
      "Price: $45,000\n",
      "Engine: Electric\n",
      "Year: 2023\n",
      "Country: United States\n",
      "Description: The Zenith Electra is a sleek and futuristic electric car designed by Tesla Motors. With a range of 300 miles on a single charge and quick acceleration, this car is perfect for eco-conscious drivers who also enjoy a touch of luxury. The interior features state-of-the-art technology, including a large touch screen display for navigation and entertainment. The Zenith Electra offers a smooth and quiet ride, making it an ideal choice for city commuting or long road trips.\n",
      "\n",
      "\n",
      "Result 2:\n",
      "Name: Zenith Epsilon\n",
      "Price: $45,000\n",
      "Engine: Electric\n",
      "Year: 2023\n",
      "Country: United States\n",
      "Description: The Zenith Epsilon is a sleek and futuristic electric car that combines cutting-edge technology with luxury. Powered by a high-capacity battery, the Epsilon boasts impressive acceleration and a long driving range. Its aerodynamic design not only enhances performance but also contributes to its striking appearance. The interior is outfitted with premium materials and the latest smart features, ensuring a comfortable and connected driving experience. With its eco-friendly nature and high performance capabilities, the Zenith Epsilon is a standout choice in the electric car market. \n",
      "\n",
      "\n",
      "Result 3:\n",
      "Name: Ford Mustang GT 2024\n",
      "Price: $45,000\n",
      "Engine: 5.0L V8\n",
      "Year: 2024\n",
      "Country: United States\n",
      "Description: The Ford Mustang GT 2024 delivers exhilarating performance with its powerful V8 engine, sporty handling, and iconic design.\n",
      "\n",
      "\n",
      "Result 4:\n",
      "Name: Thunderbolt GT\n",
      "Price: $45,000\n",
      "Engine: Electric\n",
      "Year: 2023\n",
      "Country: United States\n",
      "Description: The Thunderbolt GT is an all-electric sports car that delivers an exhilarating driving experience. With dual electric motors producing a combined 500 horsepower, this sleek and futuristic-looking car can go from 0 to 60 mph in just 3.5 seconds. The Thunderbolt GT features cutting-edge technology, including a smart infotainment system, advanced driver assistance features, and a long-range battery that provides up to 300 miles on a single charge. It's the perfect blend of performance, style, and sustainability.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Additional query for metadata (Country-specific search)\n",
    "\"\"\"\n",
    "In this step, we demonstrate querying not only for text similarity but also filtering results based on metadata like country of origin.\n",
    "\"\"\"\n",
    "# Specify the country filter\n",
    "country_filter = \"United States\"  # Replace with the desired country\n",
    "\n",
    "# Query the Chroma collection with the country filter\n",
    "results = car_collection.query(\n",
    "    query_texts=[prompt],\n",
    "    n_results=10,\n",
    "    where={\"country\": country_filter}  # Metadata filter for country\n",
    ")\n",
    "\n",
    "# Display results with country filtering and include the description\n",
    "print(f\"The user's prompt is: {prompt}\")\n",
    "for idx, metadata in enumerate(results[\"metadatas\"][0]):\n",
    "    name = metadata[\"name\"]\n",
    "    price = metadata[\"price\"]\n",
    "    engine = metadata[\"engine\"]\n",
    "    year = metadata[\"year\"]\n",
    "    country = metadata[\"country\"]\n",
    "    description = results[\"documents\"][0][idx]  # Extract the corresponding description\n",
    "\n",
    "    print(f\"\\nResult {idx + 1}:\")\n",
    "    print(f\"Name: {name}\")\n",
    "    print(f\"Price: {price}\")\n",
    "    print(f\"Engine: {engine}\")\n",
    "    print(f\"Year: {year}\")\n",
    "    print(f\"Country: {country}\")\n",
    "    print(f\"Description: {description}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7: Enriching the Output Using an LLM\n",
    "\n",
    "In this step, we enhance the user experience by generating a personalized, human-like message for the car buyer. This message is crafted by leveraging the retrieved car metadata and combining it with GPT-3.5's natural language capabilities.\n",
    "\n",
    "### Why Enrich the Output?\n",
    "1. **Personalized Experience**: Tailored messages make the recommendations more engaging and user-specific.\n",
    "2. **Improved Communication**: Highlights key features of the car in an appealing way.\n",
    "3. **Contextual Relevance**: Aligns the message with user preferences and needs.\n",
    "\n",
    "### Workflow\n",
    "- Extract car metadata such as `name`, `price`, `engine`, `year`, `manufacturer`, and `country`.\n",
    "- Pass the metadata to GPT-3.5 to generate a friendly and engaging recommendation message.\n",
    "- Display the enriched message to the user.\n",
    "\n",
    "### Code Highlights\n",
    "- **Metadata Integration**: Uses car details to craft a personalized message.\n",
    "- **LLM Usage**: GPT-3.5 generates context-aware and user-friendly output.\n",
    "- **Dynamic Messaging**: Messages are adaptable to different cars and user queries.\n",
    "\n",
    "This step demonstrates how to combine retrieval with generation to create a more interactive and valuable user experience.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Personalized Message:\n",
      "🚗🌟 Welcome to the future of driving! 🌟🚗\n",
      "\n",
      "Are you ready to experience the ultimate blend of Japanese engineering excellence and cutting-edge innovation? Introducing the stunning Toyota Corolla 2024 - a true masterpiece from the beloved car producer, Toyota. \n",
      "\n",
      "Priced at just $25,000, this sleek and stylish ride is more than just a car - it's a lifestyle statement. With its powerful 1.8L Inline-4 engine under the hood, you'll enjoy a perfect balance of performance and fuel efficiency. From smooth acceleration to seamless handling, the Corolla 2024 is designed to elevate your driving experience to new heights.\n",
      "\n",
      "Experience the future today with advanced features such as top-notch safety technologies, luxurious interior comfort, and a design that turns heads wherever you go. Trust in Toyota's legacy of reliability and innovation to deliver a ride that exceeds all expectations.\n",
      "\n",
      "Don't just drive, thrive in your Toyota Corolla 2024. Embrace the power and precision of Japanese automotive excellence. Get behind the wheel and discover a whole new world of driving pleasure. 🌟 #ToyotaCorolla2024 #DrivingTheFuture 🌟\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nThis step demonstrates how to use the retrieved car data to generate an enriched, human-like response that enhances user engagement.\\nThe message can be further personalized based on additional user preferences or context.\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 6: Enriching the output using an LLM\n",
    "\"\"\"\n",
    "We will now use the LLM to generate a personalized message to the car buyer, leveraging the retrieved car's metadata.\n",
    "This step showcases how to combine retrieval with generation for a more tailored experience.\n",
    "\"\"\"\n",
    "def generate_message_for_buyer(car_name, car_price, car_engine, car_year, car_manufacturer, car_country):\n",
    "    \"\"\"\n",
    "    Generates a personalized message for the car buyer.\n",
    "    Args:\n",
    "        car_name (str): Name of the recommended car.\n",
    "        car_price (str): Price of the recommended car.\n",
    "        car_engine (str): Engine type of the recommended car.\n",
    "        car_year (str): Year of the recommended car.\n",
    "        car_manufacturer (str): Manufacturer of the recommended car.\n",
    "        car_country (str): Country of origin of the recommended car.\n",
    "    Returns:\n",
    "        str: A personalized message for the buyer.\n",
    "    \"\"\"\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant to sell a car.\"},\n",
    "            {\"role\": \"user\", \"content\": (\n",
    "                f\"Create a friendly and engaging message for a car buyer interested in the {car_name}. \\n\"\n",
    "                f\"The user wants a car from a give {car_country} and add relevant information about this.\\n\"\n",
    "                f\"Mention its price of {car_price} and highlight the {car_engine} engine's benefits, the performance, and other key features.\\n\"\n",
    "                f\"Highlight the Year {car_year} and the Car Producer/Manufacturer {car_manufacturer} as key points.\"\n",
    "            )}\n",
    "        ],\n",
    "        max_tokens=300\n",
    "    )\n",
    "    return response['choices'][0]['message']['content'].strip()\n",
    "\n",
    "# Generate the enriched message\n",
    "enriched_message = generate_message_for_buyer(result_name, \n",
    "                                              result_price, \n",
    "                                              result_engine, \n",
    "                                              result_year, \n",
    "                                              result_manufacture,\n",
    "                                              result_country\n",
    "                                            )\n",
    "print(\"\\nPersonalized Message:\")\n",
    "print(enriched_message)\n",
    "\n",
    "\"\"\"\n",
    "This step demonstrates how to use the retrieved car data to generate an enriched, human-like response that enhances user engagement.\n",
    "The message can be further personalized based on additional user preferences or context.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7a: Generating Visual Representations for Cars\n",
    "\n",
    "In this step, we enhance the user experience by generating realistic images of the recommended cars using an AI image generation API, such as OpenAI's DALL-E. This visual representation complements the textual description, making the results more engaging and tangible for users.\n",
    "\n",
    "### Why Generate Images?\n",
    "1. **Enhanced User Experience**: Visuals provide a clearer understanding of the recommendation.\n",
    "2. **Personalization**: Images can reflect specific user queries, like model, year, or manufacturer.\n",
    "3. **Engagement**: Combining text and visuals creates a richer and more interactive system.\n",
    "\n",
    "### Workflow\n",
    "- Create a descriptive image prompt using the car's name, year, and manufacturer.\n",
    "- Use the API to generate a high-quality, realistic image based on the prompt.\n",
    "- Display the generated image alongside the recommendation.\n",
    "\n",
    "### Code Highlights\n",
    "- **Prompt Engineering**: Ensures the generated image aligns with the car's details.\n",
    "- **API Integration**: Uses OpenAI's `Image.create` method for image generation.\n",
    "- **Realistic Details**: Includes elements like showroom setting, side angles, and daylight effects.\n",
    "\n",
    "This step demonstrates how visual representations can complement the RAG system, adding depth and engagement to user interactions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Personalized Message:\n",
      "🌟 Dive into the future with the Zenith Epsilon 2023! 🚀\n",
      "\n",
      "This sleek and innovative electric ride from Zenith Motor Works is a dream come true for car enthusiasts like you. 😍 Priced at $45,000, the Zenith Epsilon is not just a car - it's an experience!\n",
      "\n",
      "Let's talk performance. The electric engine of the Zenith Epsilon ensures a smooth and powerful drive, giving you the thrill of the open road every time you hit the accelerator. 🚗⚡️ \n",
      "\n",
      "Now, let's discuss the key features that make the Zenith Epsilon stand out from the crowd. With its futuristic design, cutting-edge technology, and top-notch safety features, this car is the perfect blend of style and substance. 💫 \n",
      "\n",
      "And here's the cherry on top - the Zenith Epsilon is proudly manufactured in the United States! 🇺🇸\n",
      "\n",
      "Don't miss out on the opportunity to own this masterpiece from the future. Contact us today to schedule a test drive and take the first step towards experiencing the Zenith Epsilon 2023 magic for yourself. 🌟 #ZenithEpsilon2023 #ElectricRevolution\n",
      "\n",
      "Generated Image:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://oaidalleapiprodscus.blob.core.windows.net/private/org-NGNoGMde0ejmvkn9fXch9ZkJ/user-1pUB3Xd19WON6IAUwM2qMUVt/img-kJ6CjZJkxRXWhCvyGnBCAvXS.png?st=2024-12-09T18%3A05%3A38Z&se=2024-12-09T20%3A05%3A38Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=d505667d-d6c1-4a0a-bac7-5c84a87759f8&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-12-09T10%3A55%3A44Z&ske=2024-12-10T10%3A55%3A44Z&sks=b&skv=2024-08-04&sig=ax4Zucys%2BGNfBuMRRCminUSBZzV32agXMqqrTHVlmqw%3D\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\nThis step demonstrates how to use the retrieved car data to generate both an enriched, human-like response and a visual representation of the car, enhancing user engagement.\\nThe message and image can be further personalized based on additional user preferences or context.\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_image_for_car(car_name, car_year, car_manufacturer):\n",
    "    \"\"\"\n",
    "    Generates an image for the recommended car using DALL-E or another image generation API.\n",
    "    Args:\n",
    "        car_name (str): Name of the car.\n",
    "        car_year (str): Year of the car.\n",
    "        car_manufacturer (str): Manufacturer of the car.\n",
    "    Returns:\n",
    "        str: File path or URL of the generated image.\n",
    "    \"\"\"\n",
    "    image_prompt = (\n",
    "        f\"A full exterior view of a car from year {car_year}, manufacturer {car_manufacturer} and name {car_name} parked in a showroom. \"\n",
    "        \"Show the car from the side angle, including wheels, headlights, and body details. \"\n",
    "        \"The image should depict a realistic, high-quality photo in natural daylight.\"\n",
    "        f\"Add a plate with the the car price {car_year} and the car name {car_name}\"\n",
    "    )\n",
    "    response = openai.Image.create(\n",
    "        prompt=image_prompt,\n",
    "        n=1,\n",
    "        size=\"512x512\"  # Specify the smaller image size\n",
    "    )\n",
    "    return response[\"data\"][0][\"url\"]\n",
    "\n",
    "print(\"\\nPersonalized Message:\")\n",
    "print(enriched_message)\n",
    "\n",
    "# Generate the car image\n",
    "image_url = generate_image_for_car(result_name, result_year, result_manufacture)\n",
    "\n",
    "print(\"\\nGenerated Image:\")\n",
    "display(Image(url=image_url))\n",
    "\n",
    "\"\"\"\n",
    "This step demonstrates how to use the retrieved car data to generate both an enriched, human-like response and a visual representation of the car, enhancing user engagement.\n",
    "The message and image can be further personalized based on additional user preferences or context.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8: Reranking with LLMs\n",
    "\n",
    "Reranking is a critical component in ensuring the most relevant results are presented to users. This step introduces a robust retry mechanism that enhances the reliability of the reranking process when utilizing GPT-3.5 for scoring relevance. The retry mechanism ensures consistent results even in cases where API calls fail due to network or token errors.\n",
    "\n",
    "### Why Focus on the Reranking Mechanism?\n",
    "1. **Reliability Under Stress**: Handles transient errors from GPT-3.5 API calls with up to three retry attempts.\n",
    "2. **Contextual Accuracy**: Combines GPT-derived relevance scores with vector similarity scores for improved ranking precision.\n",
    "3. **Streamlined Results**: Logs skipped entries gracefully to maintain overall system performance and user experience.\n",
    "\n",
    "### Reranking Workflow\n",
    "- Query results from ChromaDB are passed to GPT-3.5 for relevance scoring.\n",
    "- If an error occurs during a GPT call, the retry mechanism attempts up to three calls.\n",
    "- Results with successful scores are combined with vector similarity scores to calculate a weighted ranking.\n",
    "- Entries that fail after retries are logged and skipped.\n",
    "\n",
    "### Code Highlights\n",
    "- **Retry Logic**: Built into the `rerank_gpt_call` function, ensuring a seamless fallback for errors.\n",
    "- **Combined Scoring**: Weighted scores from GPT relevance and vector similarity ensure robust ranking.\n",
    "- **Error Logging**: Keeps track of skipped results, enabling post-analysis for improvements.\n",
    "\n",
    "This enhanced reranking mechanism underpins the robustness of the RAG system, ensuring meaningful, context-aware outputs even under challenging conditions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The user's prompt is: I need a luxury sedan with a hybrid engine for a comfortable commute.\n",
      "Re-ranked Results:\n",
      "\n",
      "Rank 1:\n",
      "Name: Zenith Epsilon\n",
      "Score: 4.191220387816429\n",
      "Details: {'country': 'United States', 'engine': 'Electric', 'manufacturer': 'Zenith Motor Works', 'name': 'Zenith Epsilon', 'price': '$45,000', 'year': 2023, 'combined_score': 4.191220387816429}\n",
      "\n",
      "Rank 2:\n",
      "Name: Zenith Electra\n",
      "Score: 4.180752873420715\n",
      "Details: {'country': 'United States', 'engine': 'Electric', 'manufacturer': 'Tesla Motors', 'name': 'Zenith Electra', 'price': '$45,000', 'year': 2023, 'combined_score': 4.180752873420715}\n",
      "\n",
      "Rank 3:\n",
      "Name: Thunderbolt GT\n",
      "Score: 1.2107885479927063\n",
      "Details: {'country': 'United States', 'engine': 'Electric', 'manufacturer': 'Volt Motors', 'name': 'Thunderbolt GT', 'price': '$45,000', 'year': 2023, 'combined_score': 1.2107885479927063}\n",
      "\n",
      "Rank 4:\n",
      "Name: Ford Mustang GT 2024\n",
      "Score: 1.1997177451848984\n",
      "Details: {'country': 'United States', 'engine': '5.0L V8', 'manufacturer': 'Ford', 'name': 'Ford Mustang GT 2024', 'price': '$45,000', 'year': 2024, 'combined_score': 1.1997177451848984}\n"
     ]
    }
   ],
   "source": [
    "def rerank_gpt_call(query, description, temperature=0.3):\n",
    "    \"\"\"\n",
    "    Call GPT-3.5 to score the relevance of a car description to a query.\n",
    "    Args:\n",
    "        query (str): The original user query.\n",
    "        description (str): The description of a car.\n",
    "        temperature (float): The creativity level for the response (default is 0.3 for more deterministic results).\n",
    "    Returns:\n",
    "        int: The score.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": (\n",
    "                        \"You are an AI ranking assistant. Your task is to evaluate the relevance of a car description \"\n",
    "                        \"to a given user query. Focus on matching keywords, themes, and context.\"\n",
    "                    )\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": (\n",
    "                        f\"Query: \\\"{query}\\\"\\n\"\n",
    "                        f\"Car Description: \\\"{description}\\\"\\n\"\n",
    "                        \"On a scale from 1 to 10, where:\\n\"\n",
    "                        \"- 1 means 'completely irrelevant',\\n\"\n",
    "                        \"- 5 means 'somewhat relevant', and\\n\"\n",
    "                        \"- 10 means 'perfectly relevant',\\n\"\n",
    "                        \"rate the relevance of the car description to the query and provide only the numeric score.\"\n",
    "                    )\n",
    "                }\n",
    "            ],\n",
    "            temperature=temperature,  # Adding temperature control\n",
    "            max_tokens=10  # Ensuring minimal tokens for numeric output\n",
    "        )\n",
    "        llm_score = int(response['choices'][0]['message']['content'].strip())  # Extracting score from response\n",
    "        return llm_score\n",
    "    except Exception as e:\n",
    "        print(f\"Error during GPT call: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def rerank_results(query, results):\n",
    "    \"\"\"\n",
    "    Re-rank the results based on additional contextual evaluation.\n",
    "    Args:\n",
    "        query (str): The original user query.\n",
    "        results (dict): The results returned by ChromaDB query.\n",
    "    Returns:\n",
    "        list: Re-ranked results with metadata and scores.\n",
    "    \"\"\"\n",
    "    reranked_results = []\n",
    "    for idx, metadata in enumerate(results[\"metadatas\"][0]):\n",
    "        description = results[\"documents\"][0][idx]\n",
    "        score = results[\"distances\"][0][idx]\n",
    "\n",
    "        llm_score = None\n",
    "        attempts = 0\n",
    "        while llm_score is None and attempts < 3:\n",
    "            attempts += 1\n",
    "            llm_score = rerank_gpt_call(query, description, temperature=0.5)\n",
    "            if llm_score is None:\n",
    "                print(f\"Retrying GPT call for result {idx + 1}, attempt {attempts}.\")\n",
    "\n",
    "        if llm_score is None:\n",
    "            print(f\"Failed to process result {idx + 1} after {attempts} attempts. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Combine Chroma score and LLM score\n",
    "        combined_score = score * 0.5 + llm_score * 0.5  # Adjust weights as needed\n",
    "        metadata[\"combined_score\"] = combined_score\n",
    "        reranked_results.append((metadata, combined_score))\n",
    "\n",
    "    # Sort results by combined score\n",
    "    reranked_results = sorted(reranked_results, key=lambda x: x[1], reverse=True)\n",
    "    return reranked_results\n",
    "\n",
    "# Example usage of the reranker\n",
    "# Apply reranker to the results\n",
    "reranked = rerank_results(prompt, results)\n",
    "print(f\"The user's prompt is: {prompt}\")\n",
    "print(\"Re-ranked Results:\")\n",
    "for idx, (metadata, score) in enumerate(reranked):\n",
    "    print(f\"\\nRank {idx + 1}:\")\n",
    "    print(f\"Name: {metadata['name']}\")\n",
    "    print(f\"Score: {score}\")\n",
    "    print(f\"Details: {metadata}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reranked Personalized Message:\n",
      "🌟 Welcome Car Enthusiast! 🚗\n",
      "\n",
      "Are you ready to experience the future of driving? Introducing the stylish and cutting-edge Zenith Epsilon 2023 - the car that will truly elevate your driving experience! With a price of $45,000, this stunning electric vehicle from Zenith Motor Works offers not just a car, but a lifestyle upgrade.\n",
      "\n",
      "✨Powered by an advanced Electric engine, the Zenith Epsilon ensures a smooth and silent ride, while also being eco-friendly and wallet-friendly with its incredible efficiency. Say goodbye to gas stations and hello to hassle-free recharging!\n",
      "\n",
      "💨Get ready to be amazed by the unparalleled performance of the Zenith Epsilon. From its dynamic acceleration to precise handling, every drive feels like a thrilling adventure. Whether you're cruising around town or hitting the open road, this car delivers excitement at every turn.\n",
      "\n",
      "🔍 Key Features:\n",
      "- Year: 2023\n",
      "- Manufacturer: Zenith Motor Works\n",
      "- Electric Engine for efficiency and eco-friendliness\n",
      "- Stylish and modern design\n",
      "- Advanced safety features for peace of mind\n",
      "- Cutting-edge technology for a connected driving experience\n",
      "- Spacious interior for ultimate comfort\n",
      "\n",
      "Don't miss out on the opportunity to own the Zenith Epsilon 2023 - a true game-changer in the world of electric vehicles. Contact us today to schedule a test drive and experience the future of driving firsthand! 🌟🔌\n",
      "\n",
      "Generated Image:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://oaidalleapiprodscus.blob.core.windows.net/private/org-NGNoGMde0ejmvkn9fXch9ZkJ/user-1pUB3Xd19WON6IAUwM2qMUVt/img-rfOY8RXKv0bRZFlQQCstXS3S.png?st=2024-12-09T18%3A05%3A58Z&se=2024-12-09T20%3A05%3A58Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=d505667d-d6c1-4a0a-bac7-5c84a87759f8&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-12-09T00%3A05%3A29Z&ske=2024-12-10T00%3A05%3A29Z&sks=b&skv=2024-08-04&sig=zCiS7LgFAYCjSimKyT2u5t6ENkoqlx4gXbHbo0yoIp4%3D\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reranked_result_name = reranked[0][0][\"name\"]\n",
    "reranked_result_price = reranked[0][0][\"price\"]\n",
    "reranked_result_engine = reranked[0][0][\"engine\"]\n",
    "reranked_result_year = reranked[0][0][\"year\"]\n",
    "reranked_result_manufacture = reranked[0][0][\"manufacturer\"]\n",
    "reranked_result_country = reranked[0][0][\"country\"]\n",
    "\n",
    "\n",
    "# Generate the enriched message\n",
    "enriched_message = generate_message_for_buyer(reranked_result_name, \n",
    "                                              reranked_result_price, \n",
    "                                              reranked_result_engine, \n",
    "                                              reranked_result_year, \n",
    "                                              reranked_result_manufacture,\n",
    "                                              reranked_result_country\n",
    "                                            )\n",
    "print(\"\\nReranked Personalized Message:\")\n",
    "print(enriched_message)\n",
    "\n",
    "# Generate the car image\n",
    "reranked_image_url = generate_image_for_car(reranked_result_name, reranked_result_year, reranked_result_manufacture)\n",
    "\n",
    "print(\"\\nGenerated Image:\")\n",
    "display(Image(url=reranked_image_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
